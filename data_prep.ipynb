{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess OBD-II dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load raw data\n",
    "At this stage, your data directory should contain 'VehicularData(anonymized).csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns : Index(['Car_Id', 'Person_Id', 'Trip', 'GPS_Time', 'Device_Time', 'GPS_Long',\n",
      "       'GPS_Lat', 'GPS_Speed_Ms', 'GPS_HDOP', 'GPS_Bearing', 'Gx', 'Gy', 'Gz',\n",
      "       'G_Calibrated', 'OBD_KPL_Average', 'OBD_Trip_KPL_Average',\n",
      "       'OBD_Intake_Air_Temp_C', 'Device_Barometer_M', 'GPS_Altitude_M',\n",
      "       'OBD_Engine_Load', 'OBD_Fuel_Level', 'GPS_Accuracy_M', 'OBD_Speed_Km',\n",
      "       'GPS_Speed_Km', 'Device_Trip_Dist_Km', 'OBD_Engine_Coolant_Temp_C',\n",
      "       'OBD_Engine_RPM', 'OBD_Adapter_Voltage', 'OBD_KPL_Instant',\n",
      "       'OBD_Fuel_Flow_CCmin', 'Device_Fuel_Remaining',\n",
      "       'OBD_Ambient_Air_Temp_C', 'OBD_CO2_gkm_Average', 'OBD_CO2_gkm_Instant',\n",
      "       'Device_Cost_Km_Inst', 'Device_Cost_Km_Trip', 'OBD_Air_Pedal',\n",
      "       'Context', 'Acceleration_kmhs', 'Reaction_Time', 'Air_Drag_Force',\n",
      "       'Speed_RPM_Relation', 'KPL_Instant'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ayana\\AppData\\Local\\Temp\\ipykernel_21092\\1515038905.py:9: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df1 = pd.read_csv(dataset)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os, copy, pickle, json\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "parent = os.path.abspath('')\n",
    "dataset = os.path.join(parent, 'datasets', 'VehicularData(anonymized).csv')\n",
    "\n",
    "df1 = pd.read_csv(dataset)\n",
    "print(f\"Columns : {df1.columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop non-OBD/unnecessary columns\n",
    "Save the filtered dataframe to a separate CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns after dropping :\n",
      "Index(['Car_Id', 'Person_Id', 'OBD_KPL_Average', 'OBD_Intake_Air_Temp_C',\n",
      "       'OBD_Engine_Load', 'OBD_Fuel_Level', 'OBD_Speed_Km',\n",
      "       'OBD_Engine_Coolant_Temp_C', 'OBD_Engine_RPM', 'OBD_KPL_Instant',\n",
      "       'OBD_Fuel_Flow_CCmin', 'OBD_Ambient_Air_Temp_C', 'OBD_CO2_gkm_Average',\n",
      "       'OBD_CO2_gkm_Instant', 'OBD_Air_Pedal', 'Acceleration_kmhs',\n",
      "       'Air_Drag_Force'],\n",
      "      dtype='object')\n",
      "Count : 17\n",
      "Number of samples : 91794\n"
     ]
    }
   ],
   "source": [
    "drop_cols = ['GPS_Time', 'Device_Time', 'Trip', 'GPS_Long', 'GPS_Lat', 'GPS_Speed_Ms', 'GPS_HDOP', 'GPS_Bearing', 'Gx', 'Gy', 'Gz', 'G_Calibrated', 'OBD_Trip_KPL_Average',\n",
    "             'Device_Barometer_M', 'GPS_Altitude_M', 'GPS_Accuracy_M', 'GPS_Speed_Km', 'Device_Trip_Dist_Km', 'OBD_Adapter_Voltage', 'Device_Fuel_Remaining',\n",
    "             'Device_Cost_Km_Inst', 'Device_Cost_Km_Trip', 'Context', 'Reaction_Time', 'Speed_RPM_Relation', 'KPL_Instant']\n",
    "\n",
    "for col in drop_cols:\n",
    "    try:\n",
    "        df1.drop(col, axis=1, inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "columns = df1.columns\n",
    "print(f\"Columns after dropping :\\n{columns}\\nCount : {len(columns)}\")\n",
    "print(f\"Number of samples : {len(df1)}\")\n",
    "\n",
    "df1.to_csv(os.path.join(parent, 'datasets', 'vehicular_modified.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize the dataset\n",
    "Save to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = np.array(df1[df1['Car_Id']==1])\n",
    "data2 = np.array(df1[df1['Car_Id']==2])\n",
    "num_samples1 = len(data1)\n",
    "num_samples2 = len(data2)\n",
    "\n",
    "scalers = {}\n",
    "for c_idx, col_name in enumerate(columns):\n",
    "    if col_name in ['Car_Id', 'Person_Id']:\n",
    "        continue\n",
    "    # Fit the scaler with CarID=1 instances\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1)).fit(data1[:, c_idx].reshape(-1, 1))\n",
    "    # scaler = StandardScaler().fit(data1[:, c_idx].reshape(-1, 1))\n",
    "    data1[:, c_idx] = scaler.transform(data1[:, c_idx].reshape(-1, 1)).reshape((num_samples1,))\n",
    "\n",
    "    # Scale CarID=2 instances with trained scalers\n",
    "    data2[:, c_idx] = scaler.transform(data2[:, c_idx].reshape(-1, 1)).reshape((num_samples2,))\n",
    "\n",
    "    # Keep scaler instances for future use\n",
    "    scalers[col_name] = copy.deepcopy(scaler)\n",
    "\n",
    "# Save to JSON\n",
    "new_dataset = {}\n",
    "new_dataset['columns'] = list(columns)\n",
    "new_dataset['car1'] = data1.tolist()\n",
    "new_dataset['car2'] = data2.tolist()\n",
    "\n",
    "with open(os.path.join(parent, 'datasets', 'vehicular_modified.json'), 'w') as fp:\n",
    "    json.dump(new_dataset, fp)\n",
    "\n",
    "with open(os.path.join(parent, 'datasets', 'obd2_features_scalers.pk'), 'wb') as fp:\n",
    "    pickle.dump(scalers, fp, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Filtered CSV and JSON for sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns : ['Car_Id', 'Person_Id', 'OBD_KPL_Average', 'OBD_Intake_Air_Temp_C', 'OBD_Engine_Load', 'OBD_Fuel_Level', 'OBD_Speed_Km', 'OBD_Engine_Coolant_Temp_C', 'OBD_Engine_RPM', 'OBD_KPL_Instant', 'OBD_Fuel_Flow_CCmin', 'OBD_Ambient_Air_Temp_C', 'OBD_CO2_gkm_Average', 'OBD_CO2_gkm_Instant', 'OBD_Air_Pedal', 'Acceleration_kmhs', 'Air_Drag_Force']\n",
      "85095 17\n",
      "Index(['Car_Id', 'Person_Id', 'OBD_KPL_Average', 'OBD_Intake_Air_Temp_C',\n",
      "       'OBD_Engine_Load', 'OBD_Fuel_Level', 'OBD_Speed_Km',\n",
      "       'OBD_Engine_Coolant_Temp_C', 'OBD_Engine_RPM', 'OBD_KPL_Instant',\n",
      "       'OBD_Fuel_Flow_CCmin', 'OBD_Ambient_Air_Temp_C', 'OBD_CO2_gkm_Average',\n",
      "       'OBD_CO2_gkm_Instant', 'OBD_Air_Pedal', 'Acceleration_kmhs',\n",
      "       'Air_Drag_Force'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(parent, 'datasets', 'vehicular_modified.json'), 'r') as fp:\n",
    "    df = json.load(fp)\n",
    "columns = list(df['columns'])\n",
    "df['car1'] = np.array(df['car1'], dtype=np.float32)\n",
    "df['car2'] = np.array(df['car2'], dtype=np.float32)\n",
    "print(f\"Columns : {columns}\")\n",
    "\n",
    "data = df['car1']\n",
    "num_samples, dim = data.shape\n",
    "print(num_samples, dim)\n",
    "\n",
    "df = pd.read_csv(os.path.join(parent, 'datasets', 'vehicular_modified.csv'))\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separate Driver-wise data from JSON\n",
    "\n",
    "This will create a separate directory to store separated data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load JSON and separate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns : ['Car_Id', 'Person_Id', 'OBD_KPL_Average', 'OBD_Intake_Air_Temp_C', 'OBD_Engine_Load', 'OBD_Fuel_Level', 'OBD_Speed_Km', 'OBD_Engine_Coolant_Temp_C', 'OBD_Engine_RPM', 'OBD_KPL_Instant', 'OBD_Fuel_Flow_CCmin', 'OBD_Ambient_Air_Temp_C', 'OBD_CO2_gkm_Average', 'OBD_CO2_gkm_Instant', 'OBD_Air_Pedal', 'Acceleration_kmhs', 'Air_Drag_Force']\n"
     ]
    }
   ],
   "source": [
    "driverwise_datapath = os.path.join(parent, 'datasets', 'obd_driverwise_data')\n",
    "if not os.path.exists(driverwise_datapath):\n",
    "    os.mkdir(driverwise_datapath)\n",
    "\n",
    "with open(os.path.join(parent, 'datasets', 'vehicular_modified.json'), 'r') as fp:\n",
    "    df = json.load(fp)\n",
    "columns = list(df['columns'])\n",
    "df['car1'] = np.array(df['car1'], dtype=np.float32)\n",
    "df['car2'] = np.array(df['car2'], dtype=np.float32)\n",
    "print(f\"Columns : {columns}\")\n",
    "driver_idx = np.where(np.array(df['columns'])=='Person_Id')[0]\n",
    "\n",
    "# Car-1\n",
    "drivers = np.unique(df['car1'][:, driver_idx]).tolist()\n",
    "for driver in drivers :\n",
    "    arr_idxs = np.where(df['car1'][:, driver_idx]==driver)[0]\n",
    "    arr = df['car1'][arr_idxs, 2:]\n",
    "    np.save(os.path.join(driverwise_datapath, f\"obd_car1_driver{int(driver)}.npy\"), arr)\n",
    "\n",
    "# Car-2\n",
    "drivers = np.unique(df['car2'][:, driver_idx]).tolist()\n",
    "for driver in drivers :\n",
    "    arr_idxs = np.where(df['car2'][:, driver_idx]==driver)[0]\n",
    "    arr = df['car2'][arr_idxs, 2:]\n",
    "    np.save(os.path.join(driverwise_datapath, f\"obd_car2_driver{int(driver)}.npy\"), arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obd_car1_driver1.npy : (37519, 15)\n",
      "obd_car1_driver10.npy : (4006, 15)\n",
      "obd_car1_driver2.npy : (19930, 15)\n",
      "obd_car1_driver3.npy : (10992, 15)\n",
      "obd_car1_driver4.npy : (1193, 15)\n",
      "obd_car1_driver5.npy : (6176, 15)\n",
      "obd_car1_driver6.npy : (146, 15)\n",
      "obd_car1_driver7.npy : (1676, 15)\n",
      "obd_car1_driver8.npy : (1418, 15)\n",
      "obd_car1_driver9.npy : (2039, 15)\n",
      "obd_car2_driver1.npy : (2038, 15)\n",
      "obd_car2_driver2.npy : (1041, 15)\n",
      "obd_car2_driver3.npy : (1927, 15)\n",
      "obd_car2_driver4.npy : (1693, 15)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "parent = os.path.abspath('')\n",
    "datapath = os.path.join(parent, 'datasets', 'obd_driverwise_data')\n",
    "all_splits = [x for x in os.listdir(datapath) if 'driver' in x]\n",
    "\n",
    "for driver in all_splits:\n",
    "    X = np.load(os.path.join(datapath, driver))\n",
    "    print(f\"{driver} : {X.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create HDF5 from NPY for Lazy loading\n",
    "\n",
    "Provide a window size and create chunks of OBD data. The left (input) will be of size (N, T, D) and the right (ground truth) will be of size (N, 1, D). Furthermore, it will also divide all the chunks into train and eval.\n",
    "\n",
    "It will create different `.h5` files, one for each of `X_train_left`, `X_train_right`, `X_val_left`, and `X_val_right`. You can create one `.h5` with different fields inside that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading \"obd_car1_driver1.npy\" ...\tComplete!\n",
      "Loading \"obd_car1_driver10.npy\" ...\tComplete!\n",
      "Loading \"obd_car1_driver2.npy\" ...\tComplete!\n",
      "Loading \"obd_car1_driver3.npy\" ...\tComplete!\n",
      "Loading \"obd_car1_driver4.npy\" ...\tComplete!\n",
      "Loading \"obd_car1_driver5.npy\" ...\tComplete!\n",
      "Loading \"obd_car1_driver7.npy\" ...\tComplete!\n",
      "Loading \"obd_car1_driver8.npy\" ...\tComplete!\n",
      "Loading \"obd_car1_driver9.npy\" ...\tComplete!\n",
      "Loading \"obd_car2_driver1.npy\" ...\tComplete!\n",
      "Loading \"obd_car2_driver2.npy\" ...\tComplete!\n",
      "Loading \"obd_car2_driver3.npy\" ...\tComplete!\n",
      "Loading \"obd_car2_driver4.npy\" ...\tComplete!\n",
      "X_left : (78661, 999, 15)\tX_right : (78661, 1, 15)\n"
     ]
    }
   ],
   "source": [
    "from services import createOBDchunks\n",
    "import h5py\n",
    "\n",
    "context = 1000\n",
    "test_size = 0.15\n",
    "verbose = True\n",
    "\n",
    "X_train_left, X_train_right, X_val_left, X_val_right = createOBDchunks(datapath, context=context, test_size=test_size, verbose=verbose)\n",
    "with h5py.File(os.path.join(datapath, f'obd___X_train_left_{context}.h5'), 'w') as f:\n",
    "    f.create_dataset(\"data\", data=X_train_left)\n",
    "with h5py.File(os.path.join(datapath, f'obd___X_train_right_{context}.h5'), 'w') as f:\n",
    "    f.create_dataset(\"data\", data=X_train_right)\n",
    "with h5py.File(os.path.join(datapath, f'obd___X_val_left_{context}.h5'), 'w') as f:\n",
    "    f.create_dataset(\"data\", data=X_val_left)\n",
    "with h5py.File(os.path.join(datapath, f'obd___X_val_right_{context}.h5'), 'w') as f:\n",
    "    f.create_dataset(\"data\", data=X_val_right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset : obd ...\n",
      "Dataset loaded.\n",
      "X_train_left : ((66862, 999, 15))\n",
      "X_train_right : ((66862, 1, 15))\n",
      "X_val_left : ((11799, 999, 15))\n",
      "X_val_right : ((11799, 1, 15))\n"
     ]
    }
   ],
   "source": [
    "import os, h5py\n",
    "from utils import load_data\n",
    "\n",
    "parent = os.path.abspath('')\n",
    "data = 'data' # 'mix' \n",
    "dataset_name = \"obd\" # \"obdmix\"\n",
    "\n",
    "context = 1000\n",
    "\n",
    "print(f\"Loading dataset : {dataset_name} ...\", flush=True)\n",
    "X_train_left = load_data(os.path.join(parent, 'datasets', f'obd_driverwise_{data}', f'obd___X_train_left_{context}.h5'))\n",
    "X_train_right = load_data(os.path.join(parent, 'datasets', f'obd_driverwise_{data}', f'obd___X_train_right_{context}.h5'))\n",
    "X_val_left = load_data(os.path.join(parent, 'datasets', f'obd_driverwise_{data}', f'obd___X_val_left_{context}.h5'))\n",
    "X_val_right = load_data(os.path.join(parent, 'datasets', f'obd_driverwise_{data}', f'obd___X_val_right_{context}.h5'))\n",
    "print(f\"Dataset loaded.\", flush=True)\n",
    "\n",
    "print(f\"X_train_left : ({len(X_train_left), len(X_train_left[0]), len(X_train_left[0][0])})\")\n",
    "print(f\"X_train_right : ({len(X_train_right), len(X_train_right[0]), len(X_train_right[0][0])})\")\n",
    "print(f\"X_val_left : ({len(X_val_left), len(X_val_left[0]), len(X_val_left[0][0])})\")\n",
    "print(f\"X_val_right : ({len(X_val_right), len(X_val_right[0]), len(X_val_right[0][0])})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HDF5 of Single Instances for Inference with single instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset : obd ...\n",
      "Dataset loaded.\n"
     ]
    }
   ],
   "source": [
    "import os, h5py\n",
    "from utils import load_data\n",
    "\n",
    "parent = os.path.abspath('')\n",
    "if not os.path.exists(os.path.join(parent, 'datasets', 'sample_data')):\n",
    "    os.mkdir(os.path.join(parent, 'datasets', 'sample_data'))\n",
    "data = 'data' # 'mix' \n",
    "dataset_name = \"obd\" # \"obdmix\"\n",
    "\n",
    "context = 1000\n",
    "\n",
    "print(f\"Loading dataset : {dataset_name} ...\", flush=True)\n",
    "X_train_left = load_data(os.path.join(parent, 'datasets', f'obd_driverwise_{data}', f'obd___X_train_left_{context}.h5'))\n",
    "X_train_right = load_data(os.path.join(parent, 'datasets', f'obd_driverwise_{data}', f'obd___X_train_right_{context}.h5'))\n",
    "print(f\"Dataset loaded.\", flush=True)\n",
    "\n",
    "for i in range(5):\n",
    "    sample_left = X_train_left[i]\n",
    "    sample_right = X_train_right[i]\n",
    "    with h5py.File(os.path.join(parent, 'datasets', 'sample_data', f'sample{i}_{dataset_name}_{context}.h5'), 'w') as f:\n",
    "        f.create_dataset(\"x_l\", data=sample_left)\n",
    "        f.create_dataset(\"x_r\", data=sample_right)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
